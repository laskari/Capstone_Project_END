{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_proj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1YKC3Nj0d8_VAP61joCkPYQjes0JrBsZe",
      "authorship_tag": "ABX9TyM4QEegO/4viIP4cch4u5kc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c35922437dfc487ebe3f4902f5547283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_60ae3a55f8c149639a0f932c1f4eb4d6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c479d9bb72b04f70bd8505d2f964aa83",
              "IPY_MODEL_72e1035cf5964de1ae7293369acd8168"
            ]
          }
        },
        "60ae3a55f8c149639a0f932c1f4eb4d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c479d9bb72b04f70bd8505d2f964aa83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b2762a0ccc0b4acf805850563c2c4a65",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 12182,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 12182,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30e253b4d64a4aa58418efb9894c2a4b"
          }
        },
        "72e1035cf5964de1ae7293369acd8168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dd16d674677e40ebb4959fe7191865ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12182/12182 [00:00&lt;00:00, 127694.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9eaf8e8378e4d0dbf015a12a892aa03"
          }
        },
        "b2762a0ccc0b4acf805850563c2c4a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30e253b4d64a4aa58418efb9894c2a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd16d674677e40ebb4959fe7191865ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9eaf8e8378e4d0dbf015a12a892aa03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laskari/Capstone_Project_END/blob/main/Capstone_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UqoGK7g3ckO",
        "outputId": "eaba5f6b-d6ac-4b34-ec28-e9f8efebf03a"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "\r\n",
        "file = open('/content/drive/MyDrive/END School of AI/Datasets/END Datasets/English_Python_processed.txt',\"rt\", encoding='latin')\r\n",
        "data_complete = file.read()\r\n",
        "print(data_complete[:500])\r\n",
        "print(len(data_complete))\r\n",
        "#print(data_complete[10000:30000])\r\n",
        "data_complete =  data_complete.lower()\r\n",
        "#print(\"\\nAfter Doing Lowercase\\n\")\r\n",
        "#print(data_complete[10000:30000])\r\n",
        "\r\n",
        "#data_complete = data_complete.replace(\"   \",\"    \")\r\n",
        "#data_complete = data_complete.replace(\"     \",\"    \")\r\n",
        "#data_complete = data_complete.replace(\" # \",\"#\")\r\n",
        "#data_complete = data_complete.replace(\"  # \",\"#\")\r\n",
        "#data_complete = data_complete.replace(\"#\",\"\\n#\")\r\n",
        "data_complete = re.sub(r'\"#[0123456789]','#', data_complete)\r\n",
        "data_complete = data_complete.replace(\"\\n\\n\",\"\\n\")\r\n",
        "data_complete = data_complete.replace(\"\\n\\n\\n\",\"\\n\\n\")\r\n",
        "\r\n",
        "#print(\"\\nAfter Removing Extra Line space\\n\")\r\n",
        "#print(data_complete[10000:30000])\r\n",
        "data_com = data_complete.split('#')\r\n",
        "#print(data_com[:5])\r\n",
        "\r\n",
        "qtn_text = []\r\n",
        "prog =[]\r\n",
        "\r\n",
        "for each_code in data_com:\r\n",
        "    pr_text = each_code.split('\\n')\r\n",
        "    qtn_text.append(pr_text[0])\r\n",
        "    prog.append(pr_text[1:])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# write a python program to add two numbers \n",
            "num1 = 1.5\n",
            "num2 = 6.3\n",
            "sum = num1 + num2\n",
            "print(f'Sum: {sum}')\n",
            "\n",
            "\n",
            "# write a python function to add two user provided numbers and return the sum\n",
            "def add_two_numbers(num1, num2):\n",
            "    sum = num1 + num2\n",
            "    return sum\n",
            "\n",
            "\n",
            "# write a program to find and print the largest among three numbers\n",
            "\n",
            "num1 = 10\n",
            "num2 = 12\n",
            "num3 = 14\n",
            "if (num1 >= num2) and (num1 >= num3):\n",
            "   largest = num1\n",
            "elif (num2 >= num1) and (num2 >= num3):\n",
            "   largest = num2\n",
            "else:\n",
            "   largest = num3\n",
            "print\n",
            "1120285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRQyobB24SJZ"
      },
      "source": [
        "df = pd.DataFrame({'Program_text': qtn_text, 'Program_code': prog})"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vRK3Qcb4Yuk",
        "outputId": "d45d6345-810f-4ebc-fca3-c168036f25f7"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4650, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmC9T0Ld4nqE"
      },
      "source": [
        "import torch\r\n",
        "from torch.jit import script, trace\r\n",
        "import torch.nn as nn\r\n",
        "from torch import optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import csv\r\n",
        "from torchtext.legacy import data\r\n",
        "from torchtext.legacy.data import Field, BucketIterator\r\n",
        "import random\r\n",
        "import re\r\n",
        "import os\r\n",
        "import unicodedata\r\n",
        "import codecs\r\n",
        "from io import open\r\n",
        "import itertools\r\n",
        "import math\r\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DkxvTE14nuS"
      },
      "source": [
        "SEED = 1234\r\n",
        "\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm7FZCcD4ny4"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBfSnt254n2C",
        "outputId": "cbc80b99-0a52-4461-b884-e13ce84acd27"
      },
      "source": [
        "device"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCPvlqd_4n49"
      },
      "source": [
        "Program_code = Field(tokenize = 'spacy', \r\n",
        "            init_token = 'start', \r\n",
        "            eos_token = 'end', \r\n",
        "            lower = True, \r\n",
        "            batch_first = True)\r\n",
        "\r\n",
        "Program_text = Field(tokenize = 'spacy', \r\n",
        "            init_token = 'start', \r\n",
        "            eos_token = 'end', \r\n",
        "            lower = True, \r\n",
        "            batch_first = True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XdOFtnO4n8w"
      },
      "source": [
        "fields = [('Program_text', Program_text),('Program_code',Program_code)]\r\n",
        "example = [data.Example.fromlist([df.Program_text[i],df.Program_code[i]], fields) for i in range(df.shape[0])] \r\n",
        "dataset = data.Dataset(example, fields)\r\n",
        "\r\n",
        "(train_data, valid_data, test_data) = dataset.split(split_ratio=[0.80, 0.10, 0.10], random_state=random.seed(SEED))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGkvAfqaiNYL",
        "outputId": "0a546381-3253-4c47-d332-50181b7eb39a"
      },
      "source": [
        "print(vars(train_data.examples[2]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Program_text': [' ', 'write', 'a', 'program', 'that', 'adds', 'the', 'square', 'of', 'two', 'numbers', 'and', 'prints', 'it'], 'Program_code': ['a = 32', 'b = 21', 'result = a**2 + b**2', 'print(result)', '']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xb_0CLp4oAV"
      },
      "source": [
        "Program_text.build_vocab(train_data, min_freq = 1)\r\n",
        "Program_code.build_vocab(train_data, min_freq = 1)\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NArQAiWwE0Xh",
        "outputId": "5fd63aea-0702-460a-e0f0-681229bff859"
      },
      "source": [
        "print(\"Program_text Vocab size\", len(Program_text.vocab))\r\n",
        "print(\"Program_code Vocab size\", len(Program_code.vocab))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Program_text Vocab size 2189\n",
            "Program_code Vocab size 12182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNSe7J4z4oDu"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "\r\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\r\n",
        "    (train_data, valid_data), \r\n",
        "     sort= False,\r\n",
        "     batch_size = BATCH_SIZE,\r\n",
        "     device = device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BQrX3utDyp2"
      },
      "source": [
        "import spacy\r\n",
        "spacy_en = spacy.load('en')\r\n",
        "def Tokenize(sentence):\r\n",
        "  sentence = str(sentence).replace('\\n', '\\t\\t')\r\n",
        "  return [tok.text for tok in spacy_en.tokenizer(sentence)]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKxhIOP3DjLG"
      },
      "source": [
        "import gensim\r\n",
        "w2v_dim = 256\r\n",
        "w2v_min_count = 2\r\n",
        "w2v_window = 3\r\n",
        "target = []\r\n",
        "for sent in df['Program_code'].values:\r\n",
        "  sent_token = Tokenize(sent)\r\n",
        "  target.append(sent_token)\r\n",
        "w2v_model = gensim.models.Word2Vec(target, size = w2v_dim, window = w2v_window, min_count = w2v_min_count)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "c35922437dfc487ebe3f4902f5547283",
            "60ae3a55f8c149639a0f932c1f4eb4d6",
            "c479d9bb72b04f70bd8505d2f964aa83",
            "72e1035cf5964de1ae7293369acd8168",
            "b2762a0ccc0b4acf805850563c2c4a65",
            "30e253b4d64a4aa58418efb9894c2a4b",
            "dd16d674677e40ebb4959fe7191865ae",
            "e9eaf8e8378e4d0dbf015a12a892aa03"
          ]
        },
        "id": "ZtnYrcI5FL5d",
        "outputId": "14ca34fa-ac3b-4c73-98be-77ba1fa9ca68"
      },
      "source": [
        "from tqdm import tqdm_notebook\r\n",
        "word2vec_vectors = []\r\n",
        "for token, idx in tqdm_notebook(Program_code.vocab.stoi.items()):\r\n",
        "  if token in w2v_model.wv.vocab.keys():\r\n",
        "    word2vec_vectors.append(torch.FloatTensor(w2v_model[token]))\r\n",
        "  else:\r\n",
        "    word2vec_vectors.append(torch.zeros(w2v_dim))\r\n",
        "Program_code.vocab.set_vectors(Program_code.vocab.stoi, word2vec_vectors, w2v_dim)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c35922437dfc487ebe3f4902f5547283",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=12182.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J-cW8reENFn"
      },
      "source": [
        "w2v_model.save('embeddings.txt')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQzDyY4K4oHM"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 input_dim, \r\n",
        "                 hid_dim, \r\n",
        "                 n_layers, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim,\r\n",
        "                 dropout, \r\n",
        "                 device,\r\n",
        "                 max_length = 250):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "        #self.tok_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(Program_text.vocab.vectors))\r\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\r\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\r\n",
        "        \r\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \r\n",
        "                                                  n_heads, \r\n",
        "                                                  pf_dim,\r\n",
        "                                                  dropout, \r\n",
        "                                                  device) \r\n",
        "                                     for _ in range(n_layers)])\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, src, src_mask):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        \r\n",
        "        batch_size = src.shape[0]\r\n",
        "        src_len = src.shape[1]\r\n",
        "        \r\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\r\n",
        "        \r\n",
        "        #pos = [batch size, src len]\r\n",
        "        \r\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        for layer in self.layers:\r\n",
        "            src = layer(src, src_mask)\r\n",
        "            \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "            \r\n",
        "        return src"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpURbZPm4oLE"
      },
      "source": [
        "class EncoderLayer(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 hid_dim, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim,  \r\n",
        "                 dropout, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \r\n",
        "                                                                     pf_dim, \r\n",
        "                                                                     dropout)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, src, src_mask):\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        #src_mask = [batch size, 1, 1, src len] \r\n",
        "                \r\n",
        "        #self attention\r\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        #positionwise feedforward\r\n",
        "        _src = self.positionwise_feedforward(src)\r\n",
        "        \r\n",
        "        #dropout, residual and layer norm\r\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        return src"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5bD3V1R4oOl"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\r\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        assert hid_dim % n_heads == 0\r\n",
        "        \r\n",
        "        self.hid_dim = hid_dim\r\n",
        "        self.n_heads = n_heads\r\n",
        "        self.head_dim = hid_dim // n_heads\r\n",
        "        \r\n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\r\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\r\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, query, key, value, mask = None):\r\n",
        "        \r\n",
        "        batch_size = query.shape[0]\r\n",
        "        \r\n",
        "        #query = [batch size, query len, hid dim]\r\n",
        "        #key = [batch size, key len, hid dim]\r\n",
        "        #value = [batch size, value len, hid dim]\r\n",
        "                \r\n",
        "        Q = self.fc_q(query)\r\n",
        "        K = self.fc_k(key)\r\n",
        "        V = self.fc_v(value)\r\n",
        "        \r\n",
        "        #Q = [batch size, query len, hid dim]\r\n",
        "        #K = [batch size, key len, hid dim]\r\n",
        "        #V = [batch size, value len, hid dim]\r\n",
        "                \r\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        \r\n",
        "        #Q = [batch size, n heads, query len, head dim]\r\n",
        "        #K = [batch size, n heads, key len, head dim]\r\n",
        "        #V = [batch size, n heads, value len, head dim]\r\n",
        "                \r\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\r\n",
        "        \r\n",
        "        #energy = [batch size, n heads, query len, key len]\r\n",
        "        \r\n",
        "        if mask is not None:\r\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\r\n",
        "        \r\n",
        "        attention = torch.softmax(energy, dim = -1)\r\n",
        "                \r\n",
        "        #attention = [batch size, n heads, query len, key len]\r\n",
        "                \r\n",
        "        x = torch.matmul(self.dropout(attention), V)\r\n",
        "        \r\n",
        "        #x = [batch size, n heads, query len, head dim]\r\n",
        "        \r\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\r\n",
        "        \r\n",
        "        #x = [batch size, query len, n heads, head dim]\r\n",
        "        \r\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\r\n",
        "        \r\n",
        "        #x = [batch size, query len, hid dim]\r\n",
        "        \r\n",
        "        x = self.fc_o(x)\r\n",
        "        \r\n",
        "        #x = [batch size, query len, hid dim]\r\n",
        "        \r\n",
        "        return x, attention"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Z0FEnZ4oSB"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\r\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\r\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, hid dim]\r\n",
        "        \r\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, pf dim]\r\n",
        "        \r\n",
        "        x = self.fc_2(x)\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, hid dim]\r\n",
        "        \r\n",
        "        return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTEFKX_E4oVz"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 output_dim, \r\n",
        "                 hid_dim, \r\n",
        "                 n_layers, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim, \r\n",
        "                 dropout, \r\n",
        "                 device,\r\n",
        "                 pre_trained_emb,\r\n",
        "                 max_length = 100):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "        #self.tok_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(Program_code.vocab.vectors))\r\n",
        "        self.pre_trained_emb = pre_trained_emb\r\n",
        "        self.tok_embedding = nn.Embedding.from_pretrained(self.pre_trained_emb)\r\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\r\n",
        "        \r\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \r\n",
        "                                                  n_heads, \r\n",
        "                                                  pf_dim, \r\n",
        "                                                  dropout, \r\n",
        "                                                  device)\r\n",
        "                                     for _ in range(n_layers)])\r\n",
        "        \r\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len]\r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "                \r\n",
        "        batch_size = trg.shape[0]\r\n",
        "        trg_len = trg.shape[1]\r\n",
        "        \r\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\r\n",
        "                            \r\n",
        "        #pos = [batch size, trg len]\r\n",
        "            \r\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\r\n",
        "                \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        \r\n",
        "        for layer in self.layers:\r\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        output = self.fc_out(trg)\r\n",
        "        \r\n",
        "        #output = [batch size, trg len, output dim]\r\n",
        "            \r\n",
        "        return output, attention"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcD4nRwO4oZL"
      },
      "source": [
        "class DecoderLayer(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 hid_dim, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim, \r\n",
        "                 dropout, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \r\n",
        "                                                                     pf_dim, \r\n",
        "                                                                     dropout)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        \r\n",
        "        #self attention\r\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\r\n",
        "            \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "            \r\n",
        "        #encoder attention\r\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\r\n",
        "        # query, key, value\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\r\n",
        "                    \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        \r\n",
        "        #positionwise feedforward\r\n",
        "        _trg = self.positionwise_feedforward(trg)\r\n",
        "        \r\n",
        "        #dropout, residual and layer norm\r\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        return trg, attention"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU8WSknE4ocy"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 encoder, \r\n",
        "                 decoder, \r\n",
        "                 src_pad_idx, \r\n",
        "                 trg_pad_idx, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "        self.src_pad_idx = src_pad_idx\r\n",
        "        self.trg_pad_idx = trg_pad_idx\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "    def make_src_mask(self, src):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        \r\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\r\n",
        "\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "\r\n",
        "        return src_mask\r\n",
        "    \r\n",
        "    def make_trg_mask(self, trg):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len]\r\n",
        "        \r\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\r\n",
        "        \r\n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\r\n",
        "        \r\n",
        "        trg_len = trg.shape[1]\r\n",
        "        \r\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\r\n",
        "        \r\n",
        "        #trg_sub_mask = [trg len, trg len]\r\n",
        "            \r\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\r\n",
        "        \r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        \r\n",
        "        return trg_mask\r\n",
        "\r\n",
        "    def forward(self, src, trg):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        #trg = [batch size, trg len]\r\n",
        "                \r\n",
        "        src_mask = self.make_src_mask(src)\r\n",
        "        trg_mask = self.make_trg_mask(trg)\r\n",
        "        \r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        \r\n",
        "        enc_src = self.encoder(src, src_mask)\r\n",
        "        \r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "                \r\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        #output = [batch size, trg len, output dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        return output, attention"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwb_8IqY4ogn"
      },
      "source": [
        "INPUT_DIM = len(Program_text.vocab)\r\n",
        "OUTPUT_DIM = len(Program_code.vocab)\r\n",
        "HID_DIM = 256\r\n",
        "ENC_LAYERS = 3\r\n",
        "DEC_LAYERS = 3\r\n",
        "ENC_HEADS = 8\r\n",
        "DEC_HEADS = 8\r\n",
        "ENC_PF_DIM = 512\r\n",
        "DEC_PF_DIM = 512\r\n",
        "ENC_DROPOUT = 0.1\r\n",
        "DEC_DROPOUT = 0.1\r\n",
        "pre_trained_emb = torch.FloatTensor(Program_code.vocab.vectors)\r\n",
        "\r\n",
        "enc = Encoder(INPUT_DIM,\r\n",
        "              HID_DIM, \r\n",
        "              ENC_LAYERS, \r\n",
        "              ENC_HEADS, \r\n",
        "              ENC_PF_DIM, \r\n",
        "              ENC_DROPOUT, \r\n",
        "              device)\r\n",
        "\r\n",
        "dec = Decoder(OUTPUT_DIM, \r\n",
        "              HID_DIM, \r\n",
        "              DEC_LAYERS, \r\n",
        "              DEC_HEADS, \r\n",
        "              DEC_PF_DIM, \r\n",
        "              DEC_DROPOUT, \r\n",
        "              device, \r\n",
        "              pre_trained_emb)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI9Ydm2u4oj1"
      },
      "source": [
        "SRC_PAD_IDX = Program_text.vocab.stoi[Program_text.pad_token]\r\n",
        "TRG_PAD_IDX = Program_code.vocab.stoi[Program_code.pad_token]\r\n",
        "\r\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHTJaXIm4onU"
      },
      "source": [
        "def initialize_weights(m):\r\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\r\n",
        "        nn.init.xavier_uniform_(m.weight.data)\r\n",
        "\r\n",
        "model.apply(initialize_weights);"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_717f0Gt4oqd"
      },
      "source": [
        "LEARNING_RATE = 0.0005\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F02e3HQK4ot2"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n90PVBeh4oxk"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    for i, batch in enumerate(iterator):\r\n",
        "        \r\n",
        "        src = batch.Program_text\r\n",
        "        trg = batch.Program_code\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        output, _ = model(src, trg[:,:-1])\r\n",
        "                \r\n",
        "        #output = [batch size, trg len - 1, output dim]\r\n",
        "        #trg = [batch size, trg len]\r\n",
        "            \r\n",
        "        output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "        output = output.contiguous().view(-1, output_dim)\r\n",
        "        trg = trg[:,1:].contiguous().view(-1)\r\n",
        "                \r\n",
        "        #output = [batch size * trg len - 1, output dim]\r\n",
        "        #trg = [batch size * trg len - 1]\r\n",
        "            \r\n",
        "        loss = criterion(output, trg)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IL8dkKw4o0w"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for i, batch in enumerate(iterator):\r\n",
        "\r\n",
        "            src = batch.Program_text\r\n",
        "            trg = batch.Program_code\r\n",
        "\r\n",
        "            output, _ = model(src, trg[:,:-1])\r\n",
        "            \r\n",
        "            #output = [batch size, trg len - 1, output dim]\r\n",
        "            #trg = [batch size, trg len]\r\n",
        "            \r\n",
        "            output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "            output = output.contiguous().view(-1, output_dim)\r\n",
        "            trg = trg[:,1:].contiguous().view(-1)\r\n",
        "            \r\n",
        "            #output = [batch size * trg len - 1, output dim]\r\n",
        "            #trg = [batch size * trg len - 1]\r\n",
        "            \r\n",
        "            loss = criterion(output, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNtgJ3wu7JRl"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgSJXge17JWC",
        "outputId": "cc1ed936-131e-4228-ee55-e2877e3f886e"
      },
      "source": [
        "import time\r\n",
        "N_EPOCHS = 50\r\n",
        "CLIP = 1\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "    \r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'tut6-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 3s\n",
            "\tTrain Loss: 8.376 | Train PPL: 4340.724\n",
            "\t Val. Loss: 7.937 |  Val. PPL: 2798.872\n",
            "Epoch: 02 | Time: 0m 2s\n",
            "\tTrain Loss: 7.234 | Train PPL: 1385.240\n",
            "\t Val. Loss: 7.578 |  Val. PPL: 1955.176\n",
            "Epoch: 03 | Time: 0m 2s\n",
            "\tTrain Loss: 6.979 | Train PPL: 1073.779\n",
            "\t Val. Loss: 7.658 |  Val. PPL: 2117.130\n",
            "Epoch: 04 | Time: 0m 2s\n",
            "\tTrain Loss: 6.682 | Train PPL: 798.053\n",
            "\t Val. Loss: 7.397 |  Val. PPL: 1630.846\n",
            "Epoch: 05 | Time: 0m 2s\n",
            "\tTrain Loss: 6.295 | Train PPL: 541.645\n",
            "\t Val. Loss: 7.273 |  Val. PPL: 1440.624\n",
            "Epoch: 06 | Time: 0m 2s\n",
            "\tTrain Loss: 5.854 | Train PPL: 348.666\n",
            "\t Val. Loss: 7.066 |  Val. PPL: 1170.902\n",
            "Epoch: 07 | Time: 0m 2s\n",
            "\tTrain Loss: 5.519 | Train PPL: 249.486\n",
            "\t Val. Loss: 6.788 |  Val. PPL: 886.760\n",
            "Epoch: 08 | Time: 0m 2s\n",
            "\tTrain Loss: 5.139 | Train PPL: 170.601\n",
            "\t Val. Loss: 6.621 |  Val. PPL: 750.968\n",
            "Epoch: 09 | Time: 0m 2s\n",
            "\tTrain Loss: 4.756 | Train PPL: 116.333\n",
            "\t Val. Loss: 6.466 |  Val. PPL: 642.773\n",
            "Epoch: 10 | Time: 0m 2s\n",
            "\tTrain Loss: 4.433 | Train PPL:  84.184\n",
            "\t Val. Loss: 6.360 |  Val. PPL: 578.191\n",
            "Epoch: 11 | Time: 0m 2s\n",
            "\tTrain Loss: 4.117 | Train PPL:  61.369\n",
            "\t Val. Loss: 6.137 |  Val. PPL: 462.656\n",
            "Epoch: 12 | Time: 0m 2s\n",
            "\tTrain Loss: 3.866 | Train PPL:  47.771\n",
            "\t Val. Loss: 6.082 |  Val. PPL: 437.838\n",
            "Epoch: 13 | Time: 0m 2s\n",
            "\tTrain Loss: 3.563 | Train PPL:  35.265\n",
            "\t Val. Loss: 5.953 |  Val. PPL: 385.029\n",
            "Epoch: 14 | Time: 0m 2s\n",
            "\tTrain Loss: 3.282 | Train PPL:  26.627\n",
            "\t Val. Loss: 5.812 |  Val. PPL: 334.200\n",
            "Epoch: 15 | Time: 0m 2s\n",
            "\tTrain Loss: 3.019 | Train PPL:  20.471\n",
            "\t Val. Loss: 5.831 |  Val. PPL: 340.863\n",
            "Epoch: 16 | Time: 0m 2s\n",
            "\tTrain Loss: 2.790 | Train PPL:  16.289\n",
            "\t Val. Loss: 5.674 |  Val. PPL: 291.057\n",
            "Epoch: 17 | Time: 0m 2s\n",
            "\tTrain Loss: 2.546 | Train PPL:  12.755\n",
            "\t Val. Loss: 5.581 |  Val. PPL: 265.260\n",
            "Epoch: 18 | Time: 0m 2s\n",
            "\tTrain Loss: 2.309 | Train PPL:  10.067\n",
            "\t Val. Loss: 5.494 |  Val. PPL: 243.297\n",
            "Epoch: 19 | Time: 0m 2s\n",
            "\tTrain Loss: 2.102 | Train PPL:   8.181\n",
            "\t Val. Loss: 5.451 |  Val. PPL: 233.064\n",
            "Epoch: 20 | Time: 0m 2s\n",
            "\tTrain Loss: 1.910 | Train PPL:   6.751\n",
            "\t Val. Loss: 5.424 |  Val. PPL: 226.711\n",
            "Epoch: 21 | Time: 0m 2s\n",
            "\tTrain Loss: 1.701 | Train PPL:   5.482\n",
            "\t Val. Loss: 5.260 |  Val. PPL: 192.416\n",
            "Epoch: 22 | Time: 0m 2s\n",
            "\tTrain Loss: 1.529 | Train PPL:   4.612\n",
            "\t Val. Loss: 5.322 |  Val. PPL: 204.789\n",
            "Epoch: 23 | Time: 0m 2s\n",
            "\tTrain Loss: 1.363 | Train PPL:   3.908\n",
            "\t Val. Loss: 5.246 |  Val. PPL: 189.836\n",
            "Epoch: 24 | Time: 0m 2s\n",
            "\tTrain Loss: 1.189 | Train PPL:   3.283\n",
            "\t Val. Loss: 5.259 |  Val. PPL: 192.222\n",
            "Epoch: 25 | Time: 0m 2s\n",
            "\tTrain Loss: 1.051 | Train PPL:   2.859\n",
            "\t Val. Loss: 5.140 |  Val. PPL: 170.709\n",
            "Epoch: 26 | Time: 0m 2s\n",
            "\tTrain Loss: 0.907 | Train PPL:   2.476\n",
            "\t Val. Loss: 5.180 |  Val. PPL: 177.619\n",
            "Epoch: 27 | Time: 0m 2s\n",
            "\tTrain Loss: 0.804 | Train PPL:   2.235\n",
            "\t Val. Loss: 5.129 |  Val. PPL: 168.870\n",
            "Epoch: 28 | Time: 0m 2s\n",
            "\tTrain Loss: 0.692 | Train PPL:   1.998\n",
            "\t Val. Loss: 5.159 |  Val. PPL: 173.931\n",
            "Epoch: 29 | Time: 0m 2s\n",
            "\tTrain Loss: 0.585 | Train PPL:   1.796\n",
            "\t Val. Loss: 5.128 |  Val. PPL: 168.744\n",
            "Epoch: 30 | Time: 0m 2s\n",
            "\tTrain Loss: 0.514 | Train PPL:   1.672\n",
            "\t Val. Loss: 5.155 |  Val. PPL: 173.227\n",
            "Epoch: 31 | Time: 0m 2s\n",
            "\tTrain Loss: 0.453 | Train PPL:   1.573\n",
            "\t Val. Loss: 5.220 |  Val. PPL: 185.014\n",
            "Epoch: 32 | Time: 0m 2s\n",
            "\tTrain Loss: 0.384 | Train PPL:   1.468\n",
            "\t Val. Loss: 5.153 |  Val. PPL: 172.994\n",
            "Epoch: 33 | Time: 0m 2s\n",
            "\tTrain Loss: 0.329 | Train PPL:   1.389\n",
            "\t Val. Loss: 5.232 |  Val. PPL: 187.250\n",
            "Epoch: 34 | Time: 0m 2s\n",
            "\tTrain Loss: 0.290 | Train PPL:   1.337\n",
            "\t Val. Loss: 5.232 |  Val. PPL: 187.086\n",
            "Epoch: 35 | Time: 0m 2s\n",
            "\tTrain Loss: 0.264 | Train PPL:   1.302\n",
            "\t Val. Loss: 5.258 |  Val. PPL: 192.140\n",
            "Epoch: 36 | Time: 0m 2s\n",
            "\tTrain Loss: 0.227 | Train PPL:   1.255\n",
            "\t Val. Loss: 5.230 |  Val. PPL: 186.870\n",
            "Epoch: 37 | Time: 0m 2s\n",
            "\tTrain Loss: 0.211 | Train PPL:   1.235\n",
            "\t Val. Loss: 5.318 |  Val. PPL: 204.017\n",
            "Epoch: 38 | Time: 0m 2s\n",
            "\tTrain Loss: 0.193 | Train PPL:   1.213\n",
            "\t Val. Loss: 5.362 |  Val. PPL: 213.196\n",
            "Epoch: 39 | Time: 0m 2s\n",
            "\tTrain Loss: 0.174 | Train PPL:   1.190\n",
            "\t Val. Loss: 5.291 |  Val. PPL: 198.639\n",
            "Epoch: 40 | Time: 0m 2s\n",
            "\tTrain Loss: 0.158 | Train PPL:   1.171\n",
            "\t Val. Loss: 5.306 |  Val. PPL: 201.612\n",
            "Epoch: 41 | Time: 0m 2s\n",
            "\tTrain Loss: 0.145 | Train PPL:   1.156\n",
            "\t Val. Loss: 5.423 |  Val. PPL: 226.646\n",
            "Epoch: 42 | Time: 0m 2s\n",
            "\tTrain Loss: 0.140 | Train PPL:   1.150\n",
            "\t Val. Loss: 5.401 |  Val. PPL: 221.738\n",
            "Epoch: 43 | Time: 0m 2s\n",
            "\tTrain Loss: 0.129 | Train PPL:   1.138\n",
            "\t Val. Loss: 5.493 |  Val. PPL: 242.986\n",
            "Epoch: 44 | Time: 0m 2s\n",
            "\tTrain Loss: 0.121 | Train PPL:   1.128\n",
            "\t Val. Loss: 5.431 |  Val. PPL: 228.416\n",
            "Epoch: 45 | Time: 0m 2s\n",
            "\tTrain Loss: 0.115 | Train PPL:   1.122\n",
            "\t Val. Loss: 5.425 |  Val. PPL: 226.912\n",
            "Epoch: 46 | Time: 0m 2s\n",
            "\tTrain Loss: 0.100 | Train PPL:   1.105\n",
            "\t Val. Loss: 5.417 |  Val. PPL: 225.116\n",
            "Epoch: 47 | Time: 0m 2s\n",
            "\tTrain Loss: 0.099 | Train PPL:   1.104\n",
            "\t Val. Loss: 5.535 |  Val. PPL: 253.479\n",
            "Epoch: 48 | Time: 0m 2s\n",
            "\tTrain Loss: 0.097 | Train PPL:   1.102\n",
            "\t Val. Loss: 5.466 |  Val. PPL: 236.517\n",
            "Epoch: 49 | Time: 0m 2s\n",
            "\tTrain Loss: 0.094 | Train PPL:   1.099\n",
            "\t Val. Loss: 5.488 |  Val. PPL: 241.714\n",
            "Epoch: 50 | Time: 0m 2s\n",
            "\tTrain Loss: 0.088 | Train PPL:   1.092\n",
            "\t Val. Loss: 5.598 |  Val. PPL: 269.897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6oyDsDog9Dx"
      },
      "source": [
        "import spacy\r\n",
        "def generate_code(sentence, src_field, trg_field, model, device, max_len = 50):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "        \r\n",
        "    if isinstance(sentence, str):\r\n",
        "        nlp = spacy.load('en')\r\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\r\n",
        "        \r\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\r\n",
        "\r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\r\n",
        "    \r\n",
        "    src_mask = model.make_src_mask(src_tensor)\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\r\n",
        "\r\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\r\n",
        "\r\n",
        "    for i in range(max_len):\r\n",
        "\r\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\r\n",
        "\r\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\r\n",
        "        \r\n",
        "        with torch.no_grad():\r\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        pred_token = output.argmax(2)[:,-1].item()\r\n",
        "        \r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\r\n",
        "            break\r\n",
        "    \r\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\r\n",
        "    \r\n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iubY-lFhE_5",
        "outputId": "d182607d-8a7e-4ea9-d2a3-b0bc9324862e"
      },
      "source": [
        "Question_text = 'Write a python program to print largest of three numbers\\n '\r\n",
        "\r\n",
        "print(Question_text )\r\n",
        "\r\n",
        "translation, attention = generate_code(Question_text , Program_text, Program_code, model, device)\r\n",
        "\r\n",
        "for i in range(len(translation)):\r\n",
        "  print(end =\" \")\r\n",
        "  print(translation[i])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Write a python program to print largest of three numbers\n",
            " \n",
            " a = float(input(\"please enter the first value: \"))\n",
            " b = float(input(\"please enter the first value: \"))\n",
            " c = float(input(\"please enter the first value: \"))\n",
            " if (a > b and a > c):\n",
            "           print(\"{0} is greater than both {1} and {2}\". format(a, b, c))\n",
            " elif (b > a and b > c):\n",
            "           print(\"{0} is greater than both {1} and {2}\". format(b, a, c))\n",
            " elif (c > a and c > b):\n",
            "           print(\"{0} is greater than both {1} and {2}\". format(c, a, b))\n",
            " else:\n",
            "           print(\"either any two values or all the three values are equal\")\n",
            " \n",
            " end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb_7_6kSHg3W"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}